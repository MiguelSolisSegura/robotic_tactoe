{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class TicTacToeEnv(gymnasium.Env):\n",
    "    def __init__(self):\n",
    "        super(TicTacToeEnv, self).__init__()\n",
    "        # There are 9 possible positions to place X or O\n",
    "        self.action_space = spaces.Discrete(9)\n",
    "\n",
    "        # The observation is composed by a 3X3 grid with 3 possible states\n",
    "        self.observation_space = spaces.Box(low=0, high=2, shape=(3, 3), dtype=int)\n",
    "\n",
    "        # The environment should be initialized\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        # The board starts empty\n",
    "        self.board = np.zeros((3, 3), dtype=int)\n",
    "        self.current_player = 1\n",
    "        return self.board, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        # Get the action coordinates in the board\n",
    "        row, col = divmod(action, 3)\n",
    "\n",
    "        # Invalid move case\n",
    "        if self.board[row, col] != 0:\n",
    "            return self.board, -10, True, False, {}  \n",
    "        \n",
    "        # Valid move case\n",
    "        self.board[row, col] = self.current_player\n",
    "\n",
    "        # Check if the robot wins\n",
    "        if self._check_win(self.current_player):\n",
    "            return self.board, 1, True, False, {}  \n",
    "\n",
    "        # Check if there is a draw\n",
    "        if np.all(self.board != 0):\n",
    "            return self.board, 0, True, False, {}  \n",
    "\n",
    "        # Select the next player\n",
    "        self.current_player = 3 - self.current_player\n",
    "        return self.board, 0, False, False, {}  \n",
    "\n",
    "    def _check_win(self, player):\n",
    "        # Check for vertical and horizontal lines\n",
    "        for i in range(3):\n",
    "            if np.all(self.board[i, :] == player) or np.all(self.board[:, i] == player):\n",
    "                return True\n",
    "            \n",
    "        # Check for diagonal lines\n",
    "        if self.board[0, 0] == self.board[1, 1] == self.board[2, 2] == player or \\\n",
    "           self.board[0, 2] == self.board[1, 1] == self.board[2, 0] == player:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        clear_output(wait=False)\n",
    "        symbols = {0: ' ', 1: 'X', 2: 'O'}\n",
    "        board = self.board\n",
    "        print(\"\\n\")\n",
    "        print(f\" {symbols[board[0, 0]]} | {symbols[board[0, 1]]} | {symbols[board[0, 2]]} \")\n",
    "        print(\"---|---|---\")\n",
    "        print(f\" {symbols[board[1, 0]]} | {symbols[board[1, 1]]} | {symbols[board[1, 2]]} \")\n",
    "        print(\"---|---|---\")\n",
    "        print(f\" {symbols[board[2, 0]]} | {symbols[board[2, 1]]} | {symbols[board[2, 2]]} \")\n",
    "        print(\"\\n\")\n",
    "\n",
    "    def close(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# Create the environment\n",
    "env = DummyVecEnv([lambda: TicTacToeEnv()])\n",
    "\n",
    "# Use GPU if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Instantiate the agent\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, device=device)\n",
    "\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=100000, progress_bar=True)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_tic_tac_toe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = PPO.load(\"ppo_tic_tac_toe\")\n",
    "\n",
    "# Test the trained agent\n",
    "env = TicTacToeEnv()\n",
    "obs, info = env.reset()  # Unpack the observation and info\n",
    "done = False\n",
    "truncated = False  # Initialize truncated as False\n",
    "while not done and not truncated:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    env.render()\n",
    "\n",
    "print(\"Reward:\", reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_games = 100\n",
    "wins = 0\n",
    "draws = 0\n",
    "losses = 0\n",
    "\n",
    "for _ in range(n_games):\n",
    "    obs, info = env.reset()  # Unpack the observation and info\n",
    "    done = False\n",
    "    truncated = False  # Initialize truncated as False\n",
    "    while not done and not truncated:\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "    if reward == 1:\n",
    "        wins += 1\n",
    "    elif reward == 0:\n",
    "        draws += 1\n",
    "    else:\n",
    "        losses += 1\n",
    "\n",
    "print(f\"Wins: {wins}, Draws: {draws}, Losses: {losses}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " O | O | X \n",
      "---|---|---\n",
      "   | O |   \n",
      "---|---|---\n",
      " X | X | X \n",
      "\n",
      "\n",
      "Player 1 (X) wins!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# Load the model\n",
    "model = PPO.load(\"ppo_tic_tac_toe\")\n",
    "\n",
    "# Initialize the environment\n",
    "env = TicTacToeEnv()\n",
    "\n",
    "def human_move():\n",
    "    while True:\n",
    "        try:\n",
    "            move = int(input(\"Enter your move (0-8): \"))\n",
    "            if move < 0 or move > 8:\n",
    "                print(\"Invalid move. Move must be between 0 and 8.\")\n",
    "            elif env.board.flatten()[move] != 0:\n",
    "                print(\"Invalid move. Cell already taken.\")\n",
    "            else:\n",
    "                return move\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a number between 0 and 8.\")\n",
    "\n",
    "# Prompt the user to choose player 1 or player 2\n",
    "while True:\n",
    "    human_player = input(\"Do you want to be player 1 (X) or player 2 (O)? Enter 1 or 2: \")\n",
    "    if human_player in ['1', '2']:\n",
    "        human_player = int(human_player)\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid input. Please enter 1 or 2.\")\n",
    "\n",
    "print(f\"You are player {human_player} ({'X' if human_player == 1 else 'O'}).\")\n",
    "\n",
    "# Play against the agent\n",
    "obs, info = env.reset()\n",
    "done = False\n",
    "truncated = False\n",
    "\n",
    "while not done and not truncated:\n",
    "    env.render()\n",
    "    if env.current_player == human_player:  # Human player's turn\n",
    "        action = human_move()\n",
    "    else:  # Agent's turn\n",
    "        action, _states = model.predict(obs)\n",
    "    \n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "    if done or truncated:\n",
    "        env.render()\n",
    "        if reward == 1:\n",
    "            print(\"Player 1 (X)\" if env.current_player == 1 else \"Player 2 (O)\", \"wins!\")\n",
    "        elif reward == 0:\n",
    "            print(\"It's a draw!\")\n",
    "        else:\n",
    "            print(\"Player 1 (X)\" if env.current_player == 2 else \"Player 2 (O)\", \"wins!\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
